{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, KFold, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(\"files\"):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(\"files\", file_name)\n",
    "\n",
    "        df_name = os.path.splitext(file_name)[0]\n",
    "        globals()[df_name] = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO MISTAKE IN RETIREES CLASSIFICATION ?\n",
    "\n",
    "ids_1 = set(learn_dataset_retired_pension[\"PRIMARY_KEY\"])\n",
    "ids_2 = set(learn_dataset_retired_jobs[\"PRIMARY_KEY\"])\n",
    "ids_3 = set(learn_dataset_retired_former[\"PRIMARY_KEY\"])\n",
    "\n",
    "# Step 2: Check the equality of the IDs between datasets\n",
    "def check_sanity(ids_a, ids_b, dataset_a, dataset_b):\n",
    "    if ids_a == ids_b:\n",
    "        print(f\"Sanity check passed: {dataset_a} and {dataset_b} contain the same individuals.\")\n",
    "    else:\n",
    "        print(f\"Sanity check failed: There are differences in the individuals from {dataset_a} and {dataset_b}\")\n",
    "\n",
    "check_sanity(ids_1, ids_2, \"Dataset 1\", \"Dataset 2\")\n",
    "check_sanity(ids_1, ids_3, \"Dataset 1\", \"Dataset 3\")\n",
    "check_sanity(ids_2, ids_3, \"Dataset 2\", \"Dataset 3\")\n",
    "\n",
    "not_common_ids_1 = ids_1.symmetric_difference(ids_3)\n",
    "print(f\"Number of people that are not common to dataset 1 and 3: {len(not_common_ids_1)}\")\n",
    "\n",
    "not_common_ids_2 = ids_2.symmetric_difference(ids_3)\n",
    "print(f\"Number of people that are not common to dataset 2 and 3: {len(not_common_ids_2)}\")\n",
    "\n",
    "print(\"These individuals are in dataset3 but not in dataset1:\", ids_3 - ids_1)\n",
    "print(\"These individuals are in dataset3 but not in dataset2:\", ids_3 - ids_2)\n",
    "\n",
    "#We are OK, it just that the the dataset 3 has more data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sports\n",
    "learn_dataset_sport = pd.merge(learn_dataset_sport, code_Sports, left_on=\"Sports\", right_on=\"Code\")\n",
    "learn_dataset_sport[\"Sports_Category\"] = learn_dataset_sport[\"Categorie\"]\n",
    "learn_sports = learn_dataset_sport[[\"PRIMARY_KEY\", \"Sports_Category\"]]\n",
    "\n",
    "# departments into regions\n",
    "def merge_and_extract_region(df, merge_column, region_column_name):\n",
    "    df = pd.merge(df, departments, left_on=merge_column, right_on=\"DEP\")\n",
    "    df[region_column_name] = df[\"REG\"]\n",
    "    df.drop([\"Nom du département\", \"REG\", \"DEP\", merge_column], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "learn_dataset_job = merge_and_extract_region(\n",
    "    learn_dataset_job, merge_column=\"JOB_DEP\", region_column_name=\"REG_JOB\"\n",
    ")\n",
    "\n",
    "learn_dataset_retired_jobs = merge_and_extract_region(\n",
    "    learn_dataset_retired_jobs, merge_column=\"JOB_DEP\", region_column_name=\"REG_JOB\"\n",
    ")\n",
    "\n",
    "learn_dataset_retired_jobs = merge_and_extract_region(\n",
    "    learn_dataset_retired_jobs, merge_column=\"FORMER_DEP\", region_column_name=\"REG_FORMER\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Economic sector into fewer categories (and numeric instead of object/string)\n",
    "def sector_mapping(nace_code):\n",
    "    if nace_code == \"AZ\":  \n",
    "        return \"Agriculture, forestry and fishing)\"\n",
    "    elif \"BZ\" <= nace_code <= \"EZ\":\n",
    "        return \"Manufacturing, mining and quarrying and other industrial activities\"\n",
    "    elif nace_code == \"FZ\": \n",
    "        return \"Construction\"\n",
    "    elif \"GZ\" <= nace_code <= \"IZ\":  \n",
    "        return \"Wholesale and retail trade, transportation and storage, accommodation and food service activities\"\n",
    "    elif \"JA\" <= nace_code <= \"JC\":\n",
    "        return \"Information and communication\"\n",
    "    elif nace_code == \"KZ\": \n",
    "        return \"Financial and insurance activities\"\n",
    "    elif nace_code == \"LZ\": \n",
    "        return \"Real estate activities\"\n",
    "    elif \"MA\" <= nace_code <= \"NZ\":\n",
    "        return \"Professional, scientific, technical, administrative and support service activities\"\n",
    "    elif \"OZ\" <= nace_code <= \"QB\":\n",
    "        return \"Public administration and defence, education, human health and social work activities\"\n",
    "    elif \"RZ\" <= nace_code <= \"UZ\":\n",
    "        return \"Other services activities\"\n",
    "    else:\n",
    "        return \"Unknown Sector\"\n",
    "\n",
    "code_Economic_sector[\"Nomenclature\"] = code_Economic_sector[\"Code\"].map(sector_mapping)\n",
    "code_Economic_sector[\"Economic_sector_num\"] = pd.factorize(code_Economic_sector[\"Nomenclature\"])[0] + 1\n",
    "\n",
    "#code_emp_contract[\"emp_contract_num\"] = pd.factorize(code_emp_contract[\"Code\"])[0] + 1\n",
    "code_HIGHEST_CREDENTIAL[\"HIGHEST_CREDENTIAL_num\"] = pd.factorize(code_HIGHEST_CREDENTIAL[\"Code\"])[0] + 1\n",
    "code_act[\"act_num\"] = pd.factorize(code_act[\"Code\"])[0] + 1\n",
    "\n",
    "#learn_dataset_emp_contract = pd.merge(learn_dataset_emp_contract, code_emp_contract, left_on=\"emp_contract\",  right_on=\"Code\")\n",
    "#learn_dataset_emp_contract.drop([\"Code\", \"Libellé\"], axis=1, inplace=True)\n",
    "#replace this with one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_data = learn_dataset\n",
    "learn_data = learn_data[['target'] + [col for col in learn_data.columns if col != 'target']]\n",
    "\n",
    "learn_data = pd.merge(learn_data, code_act, left_on=\"act\", right_on=\"Code\", how=\"left\")\n",
    "learn_data.drop([\"Code\", \"Libellé\"], axis=1, inplace=True)\n",
    "learn_data = pd.merge(learn_data, code_HIGHEST_CREDENTIAL, left_on=\"HIGHEST_CREDENTIAL\", right_on=\"Code\", how=\"left\")\n",
    "learn_data.drop([\"Code\", \"Libellé\", \"HIGHEST_CREDENTIAL\"], axis=1, inplace=True)\n",
    "\n",
    "learn_data = pd.merge(learn_data, city_pop, on=\"INSEE_CODE\", how=\"left\")\n",
    "learn_data = pd.merge(learn_data, city_loc, on=\"INSEE_CODE\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_dfs = [learn_dataset_emp_contract, learn_dataset_job, learn_dataset_retired_former, learn_dataset_retired_jobs, learn_dataset_retired_pension, learn_sports]\n",
    "\n",
    "for df in learn_dfs:\n",
    "    learn_data = pd.merge(learn_data, df, on=\"PRIMARY_KEY\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_columns(col_x, col_y):\n",
    "    return col_x.fillna(col_y) if col_y is not None else col_x\n",
    "\n",
    "for column in learn_data.columns:\n",
    "    if column.endswith('_x'):\n",
    "        base_column = column[:-2]  # Remove `_x` suffix\n",
    "        y_column = base_column + '_y'\n",
    "        if y_column in learn_data.columns:\n",
    "            # Combine the columns\n",
    "            learn_data[base_column] = combine_columns(learn_data[column], learn_data[y_column])\n",
    "            # Drop the original `_x` and `_y` columns\n",
    "            learn_data = learn_data.drop(columns=[column, y_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def household_num(value):\n",
    "    parts = value.split('|')  # Split the value by '|'\n",
    "    if parts[1] in {'1', '2', '3'}:  # For M|1|-- to M|3|--\n",
    "        return int(parts[1])\n",
    "    elif parts[1] == '4':  # For M|4|1 to M|4|4\n",
    "        return 4 + (int(parts[2]) - 1)  # 4 + (1-1), 4 + (2-1), etc.\n",
    "    return None  # Handle unexpected cases gracefully\n",
    "\n",
    "code_HOUSEHOLD_TYPE['HOUSEHOLD_TYPE_num'] = code_HOUSEHOLD_TYPE['Code'].apply(household_num)\n",
    "learn_data['HOUSEHOLD_TYPE'] = learn_data['HOUSEHOLD_TYPE'].apply(household_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_data[\"JOB_42_og\"] = learn_data[\"JOB_42\"]\n",
    "learn_data[\"FORMER_JOB_42_og\"] = learn_data[\"FORMER_JOB_42\"]\n",
    "learn_data[\"JOB_42\"] = learn_data[\"JOB_42\"].str.extract(r'csp_(\\d+)_')[0].astype(int)\n",
    "learn_data[\"FORMER_JOB_42\"] = learn_data[\"FORMER_JOB_42\"].str.extract(r'csp_(\\d+)_')[0].astype(\"Int64\")\n",
    "learn_data[\"employee_count\"] = learn_data[\"employee_count\"].str.extract(r'tr_(\\d)')[0].astype(\"Int64\")\n",
    "learn_data[\"Employer_category\"] = learn_data[\"Employer_category\"].str.extract(r'ct_(\\d)')[0].astype(\"Int64\")\n",
    "\n",
    "learn_data = pd.merge(learn_data, code_Economic_sector, left_on=\"Economic_sector\", right_on=\"Code\", how=\"left\")\n",
    "\n",
    "learn_data = pd.merge(learn_data, code_work_description_map, left_on=\"work_description\", right_on=\"N3\", how=\"left\")\n",
    "learn_data.drop([\"work_description\", \"N3\", \"N2\"], axis=1, inplace=True)\n",
    "learn_data[\"N1\"] = learn_data[\"N1\"].str.extract(r'csp_(\\d)')[0].astype(\"Int64\")\n",
    "learn_data.rename(columns={\"N1\": \"work_description\"}, inplace=True)\n",
    "\n",
    "learn_data[\"emp_contract\"] = combine_columns(learn_data[\"emp_contract\"], learn_data[\"former_emp_contract\"])\n",
    "learn_data[\"Pay\"] = combine_columns(learn_data[\"Pay\"], learn_data[\"RETIREMENT_PAY\"])\n",
    "#learn_data['is_retired'] = (learn_data['JOB_42'] == 7).astype(int)\n",
    "#learn_data['is_unemployed'] = (learn_data['act'].str.startswith('TACT2_') & (learn_data['act'] != 'TACT2_1')).astype(int)\n",
    "#learn_data['is_unemployed'] = (learn_data['act'] == 'TACT1_2').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_retirement_age():\n",
    "    global learn_data  # Modify the global learn_data DataFrame\n",
    "    \n",
    "    # Ensure the retirement_age column is numeric\n",
    "    learn_data['retirement_age'] = pd.to_numeric(learn_data['retirement_age'], errors='coerce')\n",
    "    \n",
    "    # Define the bins and corresponding labels\n",
    "    bins = [0, 57, 60, 61, 63, 65, float('inf')]  # Specify edges for the ranges\n",
    "    labels = ['<57', '57-59', '60', '61-62', '63-64', '65+']  # Labels for ranges\n",
    "\n",
    "    # Initial categorization with pd.cut\n",
    "    learn_data['retirement_age_cat'] = pd.cut(\n",
    "        learn_data['retirement_age'], \n",
    "        bins=bins, \n",
    "        labels=labels, \n",
    "        right=False,  # Left-closed intervals\n",
    "        include_lowest=True\n",
    "    )\n",
    "\n",
    "\n",
    "    # Ensure missing values in retirement_age_cat are handled properly\n",
    "    learn_data['retirement_age_cat'] = learn_data['retirement_age_cat'].astype(object)  # Avoid ambiguity with NA\n",
    "    \n",
    "    # Handle exact matches for 60 and 65\n",
    "    learn_data.loc[learn_data['retirement_age'] == 60, 'retirement_age_cat'] = '60'\n",
    "\n",
    "# Call the function\n",
    "categorize_retirement_age()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types\n",
    "learn_data[\"sex\"] = pd.factorize(learn_data[\"sex\"])[0]\n",
    "learn_data[\"studying\"] = learn_data[\"studying\"].astype(\"int64\")\n",
    "#or learn_data[\"Sports_Category\"] = pd.to_numeric(learn_data[\"Sports_Category\"], errors='coerce').astype(\"Int64\")\n",
    "learn_data[\"Sports_Category\"] = learn_data[\"Sports_Category\"].fillna(0).astype(\"int64\")\n",
    "learn_data[\"REG_JOB\"] = pd.to_numeric(learn_data[\"REG_JOB\"], errors='coerce').astype('Int64')\n",
    "learn_data[\"REG_FORMER\"] = pd.to_numeric(learn_data[\"REG_FORMER\"], errors='coerce').astype('Int64')\n",
    "learn_data[\"retirement_age\"] = pd.to_numeric(learn_data[\"retirement_age\"], errors='coerce').astype('Int64')\n",
    "learn_data[\"WORKING_HOURS\"] = pd.to_numeric(learn_data[\"WORKING_HOURS\"], errors='coerce').astype('Int64')\n",
    "learn_data[\"Economic_sector_num\"] = pd.to_numeric(learn_data[\"Economic_sector_num\"], errors='coerce').astype('Int64')\n",
    "learn_data[\"Pay\"] = pd.to_numeric(learn_data[\"Pay\"], errors='coerce').astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_na_with_category(column_name):\n",
    "    global learn_data  # Ensures we modify the global learn_data directly\n",
    "\n",
    "    # Convert the column to categorical\n",
    "    learn_data[column_name] = learn_data[column_name].astype('category')\n",
    "    \n",
    "    # Define categories to add\n",
    "    additional_categories = ['Unemployed', 'Retired_Missing', 'Employed_Missing']\n",
    "    \n",
    "    # Add the specified categories\n",
    "    learn_data[column_name] = learn_data[column_name].cat.add_categories(additional_categories)\n",
    "    \n",
    "    learn_data.loc[(learn_data[column_name].isna()) & (learn_data['JOB_42'] == 7), column_name] = 'Retired_Missing'\n",
    "    learn_data.loc[(learn_data[column_name].isna()) & (learn_data['act_num'] == 1), column_name] = 'Employed_Missing'\n",
    "    learn_data.loc[(learn_data[column_name].isna()) & ((learn_data['JOB_42'] == 8) | (learn_data['act_num'] == 2)), column_name] = 'Unemployed'\n",
    "    #learn_data[column_name] = learn_data[column_name].fillna(\"Unemployed\")\n",
    "\n",
    "replace_na_with_category(\"emp_contract\")\n",
    "replace_na_with_category(\"TYPE_OF_CONTRACT\")\n",
    "replace_na_with_category(\"WORK_CONDITION\")\n",
    "replace_na_with_category(\"labor_force_status\")\n",
    "replace_na_with_category(\"Economic_sector_num\")\n",
    "replace_na_with_category(\"REG_JOB\")\n",
    "replace_na_with_category(\"REG_FORMER\")\n",
    "replace_na_with_category(\"work_description\")\n",
    "replace_na_with_category(\"retirement_age_cat\")\n",
    "#do last after imputing\n",
    "#replace_na_with_category(\"Employer_category\") #need numbers only\n",
    "#replace_na_with_category(\"employee_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jidijmqzeswf"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
