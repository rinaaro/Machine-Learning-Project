{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, linear_model\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, KFold, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score,  mean_squared_error\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(\"files\"):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(\"files\", file_name)\n",
    "\n",
    "        df_name = os.path.splitext(file_name)[0]\n",
    "        globals()[df_name] = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplification of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge sports data and extract sports categories\n",
    "def extract_sports_category(dataset, sports_code):\n",
    "    merged = pd.merge(dataset, sports_code, left_on=\"Sports\", right_on=\"Code\")\n",
    "    merged[\"Sports_Category\"] = merged[\"Categorie\"]\n",
    "    return merged[[\"PRIMARY_KEY\", \"Sports_Category\"]]\n",
    "\n",
    "learn_sports = extract_sports_category(learn_dataset_sport, code_Sports)\n",
    "test_sports = extract_sports_category(test_dataset_sport, code_Sports)\n",
    "\n",
    "# Merge departments into regions and extract relevant region columns\n",
    "def merge_and_extract_region(df, merge_column, region_column_name):\n",
    "    merged = pd.merge(df, departments, left_on=merge_column, right_on=\"DEP\")\n",
    "    merged[region_column_name] = merged[\"REG\"]\n",
    "    return merged.drop([\"Nom du département\", \"REG\", \"DEP\", merge_column], axis=1)\n",
    "\n",
    "learn_dataset_job = merge_and_extract_region(learn_dataset_job, \"JOB_DEP\", \"REG_JOB\")\n",
    "learn_dataset_retired_jobs = merge_and_extract_region(learn_dataset_retired_jobs, \"JOB_DEP\", \"REG_JOB\")\n",
    "learn_dataset_retired_jobs = merge_and_extract_region(learn_dataset_retired_jobs, \"FORMER_DEP\", \"REG_FORMER\")\n",
    "\n",
    "test_dataset_job = merge_and_extract_region(test_dataset_job, \"JOB_DEP\", \"REG_JOB\")\n",
    "test_dataset_retired_jobs = merge_and_extract_region(test_dataset_retired_jobs, \"JOB_DEP\", \"REG_JOB\")\n",
    "test_dataset_retired_jobs = merge_and_extract_region(test_dataset_retired_jobs, \"FORMER_DEP\", \"REG_FORMER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Economic sector into fewer categories (and numeric instead of object/string)\n",
    "def sector_mapping(nace_code):\n",
    "    if nace_code == \"AZ\":  \n",
    "        return \"Agriculture, forestry and fishing)\"\n",
    "    elif \"BZ\" <= nace_code <= \"EZ\":\n",
    "        return \"Manufacturing, mining and quarrying and other industrial activities\"\n",
    "    elif nace_code == \"FZ\": \n",
    "        return \"Construction\"\n",
    "    elif \"GZ\" <= nace_code <= \"IZ\":  \n",
    "        return \"Wholesale and retail trade, transportation and storage, accommodation and food service activities\"\n",
    "    elif \"JA\" <= nace_code <= \"JC\":\n",
    "        return \"Information and communication\"\n",
    "    elif nace_code == \"KZ\": \n",
    "        return \"Financial and insurance activities\"\n",
    "    elif nace_code == \"LZ\": \n",
    "        return \"Real estate activities\"\n",
    "    elif \"MA\" <= nace_code <= \"NZ\":\n",
    "        return \"Professional, scientific, technical, administrative and support service activities\"\n",
    "    elif \"OZ\" <= nace_code <= \"QB\":\n",
    "        return \"Public administration and defence, education, human health and social work activities\"\n",
    "    elif \"RZ\" <= nace_code <= \"UZ\":\n",
    "        return \"Other services activities\"\n",
    "    else:\n",
    "        return \"Unknown Sector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_Economic_sector[\"Nomenclature\"] = code_Economic_sector[\"Code\"].map(sector_mapping)\n",
    "code_Economic_sector[\"Economic_sector_num\"] = pd.factorize(code_Economic_sector[\"Nomenclature\"])[0] + 1\n",
    "\n",
    "code_HIGHEST_CREDENTIAL[\"HIGHEST_CREDENTIAL_num\"] = pd.factorize(code_HIGHEST_CREDENTIAL[\"Code\"])[0] + 1\n",
    "code_act[\"act_num\"] = pd.factorize(code_act[\"Code\"])[0] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_data = learn_dataset\n",
    "\n",
    "learn_data = pd.merge(learn_data, code_act, left_on=\"act\", right_on=\"Code\", how=\"left\")\n",
    "learn_data.drop([\"Code\", \"Libellé\"], axis=1, inplace=True)\n",
    "learn_data = pd.merge(learn_data, code_HIGHEST_CREDENTIAL, left_on=\"HIGHEST_CREDENTIAL\", right_on=\"Code\", how=\"left\")\n",
    "learn_data.drop([\"Code\", \"Libellé\", \"HIGHEST_CREDENTIAL\"], axis=1, inplace=True)\n",
    "\n",
    "#for imputation fitting\n",
    "learn_data = pd.merge(learn_data, city_pop, on=\"INSEE_CODE\", how=\"left\")\n",
    "learn_data = pd.merge(learn_data, city_loc, on=\"INSEE_CODE\", how=\"left\")\n",
    "\n",
    "\n",
    "test_data = test_dataset\n",
    "\n",
    "test_data = pd.merge(test_data, code_act, left_on=\"act\", right_on=\"Code\", how=\"left\")\n",
    "test_data.drop([\"Code\", \"Libellé\"], axis=1, inplace=True)\n",
    "test_data = pd.merge(test_data, code_HIGHEST_CREDENTIAL, left_on=\"HIGHEST_CREDENTIAL\", right_on=\"Code\", how=\"left\")\n",
    "test_data.drop([\"Code\", \"Libellé\", \"HIGHEST_CREDENTIAL\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_dfs = [learn_dataset_emp_contract, learn_dataset_job, learn_dataset_retired_former, learn_dataset_retired_jobs, learn_dataset_retired_pension, learn_sports]\n",
    "test_dfs = [test_dataset_emp_contract, test_dataset_job, test_dataset_retired_former, test_dataset_retired_jobs, test_dataset_retired_pension, test_sports]\n",
    "\n",
    "for df in learn_dfs:\n",
    "    learn_data = pd.merge(learn_data, df, on=\"PRIMARY_KEY\", how=\"outer\")\n",
    "\n",
    "for df in test_dfs:\n",
    "    test_data = pd.merge(test_data, df, on=\"PRIMARY_KEY\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine columns ending with `_x` and `_y` into a single base column\n",
    "def combine_duplicate_columns(dataframe):\n",
    "    for column in dataframe.columns:\n",
    "        if column.endswith('_x'):\n",
    "            base_column = column[:-2]  # Remove `_x` suffix\n",
    "            y_column = base_column + '_y'\n",
    "            if y_column in dataframe.columns:\n",
    "                # Combine the `_x` and `_y` columns\n",
    "                dataframe[base_column] = dataframe[column].fillna(dataframe[y_column])\n",
    "                # Drop the original `_x` and `_y` columns\n",
    "                dataframe.drop(columns=[column, y_column], inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "# Apply the function to both datasets\n",
    "learn_data = combine_duplicate_columns(learn_data)\n",
    "test_data = combine_duplicate_columns(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting - for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def household_num(value):\n",
    "    parts = value.split('|')  # Split the value by '|'\n",
    "    if parts[1] in {'1', '2', '3'}:  # For M|1|-- to M|3|--\n",
    "        return int(parts[1])\n",
    "    elif parts[1] == '4':  # For M|4|1 to M|4|4\n",
    "        return 4 + (int(parts[2]) - 1)  # 4 + (1-1), 4 + (2-1), etc.\n",
    "    return None  # Handle unexpected cases gracefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_HOUSEHOLD_TYPE['HOUSEHOLD_TYPE_num'] = code_HOUSEHOLD_TYPE['Code'].apply(household_num)\n",
    "learn_data['HOUSEHOLD_TYPE'] = learn_data['HOUSEHOLD_TYPE'].apply(household_num)\n",
    "test_data['HOUSEHOLD_TYPE'] = test_data['HOUSEHOLD_TYPE'].apply(household_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess dataset\n",
    "def preprocess_employee_data(data, economic_sector_code, work_description_map):\n",
    "    # Extract numeric values from specific columns\n",
    "    data[\"employee_count\"] = data[\"employee_count\"].str.extract(r'tr_(\\d)')[0].astype(\"Int64\")\n",
    "    data[\"Employer_category\"] = data[\"Employer_category\"].str.extract(r'ct_(\\d)')[0].astype(\"Int64\")\n",
    "    \n",
    "    # Merge with economic sector codes\n",
    "    data = pd.merge(data, economic_sector_code, left_on=\"Economic_sector\", right_on=\"Code\", how=\"left\")\n",
    "    \n",
    "    # Merge with work description map and clean up columns\n",
    "    data = pd.merge(data, work_description_map, left_on=\"work_description\", right_on=\"N3\", how=\"left\")\n",
    "    data.drop([\"work_description\", \"N3\", \"N2\"], axis=1, inplace=True)\n",
    "    data[\"N1\"] = data[\"N1\"].str.extract(r'csp_(\\d)')[0].astype(\"Int64\")\n",
    "    data.rename(columns={\"N1\": \"work_description\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_data = preprocess_employee_data(learn_data, code_Economic_sector, code_work_description_map)\n",
    "test_data = preprocess_employee_data(test_data, code_Economic_sector, code_work_description_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(learn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
