{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(\"files\"):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(\"files\", file_name)\n",
    "\n",
    "        df_name = os.path.splitext(file_name)[0]\n",
    "        globals()[df_name] = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs with missing data: learn_dataset_job, learn_dataset_retired_jobs, test_dataset_job, test_dataset_retired_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplification of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sports\n",
    "learn_dataset_sport = pd.merge(learn_dataset_sport, code_Sports, left_on=\"Sports\", right_on=\"Code\")\n",
    "learn_dataset_sport[\"Sports_Category\"] = learn_dataset_sport[\"Categorie\"]\n",
    "learn_sports = learn_dataset_sport[[\"PRIMARY_KEY\", \"Sports_Category\"]]\n",
    "\n",
    "# departments into regions\n",
    "def merge_and_extract_region(df, merge_column, region_column_name):\n",
    "    df = pd.merge(df, departments, left_on=merge_column, right_on=\"DEP\")\n",
    "    df[region_column_name] = df[\"REG\"]\n",
    "    df.drop([\"Nom du département\", \"REG\", \"DEP\", merge_column], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "learn_dataset_job = merge_and_extract_region(\n",
    "    learn_dataset_job, merge_column=\"JOB_DEP\", region_column_name=\"REG_JOB\"\n",
    ")\n",
    "\n",
    "learn_dataset_retired_jobs = merge_and_extract_region(\n",
    "    learn_dataset_retired_jobs, merge_column=\"JOB_DEP\", region_column_name=\"REG_JOB\"\n",
    ")\n",
    "\n",
    "learn_dataset_retired_jobs = merge_and_extract_region(\n",
    "    learn_dataset_retired_jobs, merge_column=\"FORMER_DEP\", region_column_name=\"REG_FORMER\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Economic sector into fewer categories (and numeric instead of object/string)\n",
    "def sector_mapping(nace_code):\n",
    "    if nace_code == \"AZ\":  \n",
    "        return \"Agriculture, forestry and fishing)\"\n",
    "    elif \"BZ\" <= nace_code <= \"EZ\":\n",
    "        return \"Manufacturing, mining and quarrying and other industrial activities\"\n",
    "    elif nace_code == \"FZ\": \n",
    "        return \"Construction\"\n",
    "    elif \"GZ\" <= nace_code <= \"IZ\":  \n",
    "        return \"Wholesale and retail trade, transportation and storage, accommodation and food service activities\"\n",
    "    elif \"JA\" <= nace_code <= \"JC\":\n",
    "        return \"Information and communication\"\n",
    "    elif nace_code == \"KZ\": \n",
    "        return \"Financial and insurance activities\"\n",
    "    elif nace_code == \"LZ\": \n",
    "        return \"Real estate activities\"\n",
    "    elif \"MA\" <= nace_code <= \"NZ\":\n",
    "        return \"Professional, scientific, technical, administrative and support service activities\"\n",
    "    elif \"OZ\" <= nace_code <= \"QB\":\n",
    "        return \"Public administration and defence, education, human health and social work activities\"\n",
    "    elif \"RZ\" <= nace_code <= \"UZ\":\n",
    "        return \"Other services activities\"\n",
    "    else:\n",
    "        return \"Unknown Sector\"\n",
    "\n",
    "code_Economic_sector[\"Nomenclature\"] = code_Economic_sector[\"Code\"].map(sector_mapping)\n",
    "code_Economic_sector[\"Economic_sector_num\"] = pd.factorize(code_Economic_sector[\"Nomenclature\"])[0] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_dfs = [learn_dataset_emp_contract, learn_dataset_job, learn_dataset_retired_former, learn_dataset_retired_jobs, learn_dataset_retired_pension, learn_sports]\n",
    "\n",
    "learn_data = learn_dataset\n",
    "\n",
    "for df in learn_dfs:\n",
    "    learn_data = pd.merge(learn_data, df, on=\"PRIMARY_KEY\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_columns(col_x, col_y):\n",
    "    return col_x.fillna(col_y) if col_y is not None else col_x\n",
    "\n",
    "for column in learn_data.columns:\n",
    "    if column.endswith('_x'):\n",
    "        base_column = column[:-2]  # Remove `_x` suffix\n",
    "        y_column = base_column + '_y'\n",
    "        if y_column in learn_data.columns:\n",
    "            # Combine the columns\n",
    "            learn_data[base_column] = combine_columns(learn_data[column], learn_data[y_column])\n",
    "            # Drop the original `_x` and `_y` columns\n",
    "            learn_data = learn_data.drop(columns=[column, y_column])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_data = pd.merge(learn_data, code_Economic_sector, left_on=\"Economic_sector\", right_on=\"Code\", how=\"left\")\n",
    "\n",
    "learn_data = pd.merge(learn_data, code_work_description_map, left_on=\"work_description\", right_on=\"N3\", how=\"left\")\n",
    "learn_data.drop([\"work_description\", \"N3\", \"N2\"], axis=1, inplace=True)\n",
    "learn_data[\"N1\"] = learn_data[\"N1\"].str.extract(r'csp_(\\d)')[0].astype(\"Int64\")\n",
    "learn_data.rename(columns={\"N1\": \"work_description\"}, inplace=True)\n",
    "\n",
    "learn_data[\"emp_contract\"] = combine_columns(learn_data[\"emp_contract\"], learn_data[\"former_emp_contract\"])\n",
    "learn_data[\"Pay\"] = combine_columns(learn_data[\"Pay\"], learn_data[\"RETIREMENT_PAY\"])\n",
    "learn_data['is_retired'] = learn_data['JOB_42'].str.startswith('csp_7').astype(int)\n",
    "learn_data['is_unemployed'] = (learn_data['act'].str.startswith('TACT2_') & (learn_data['act'] != 'TACT2_1')).astype(int)\n",
    "#learn_data['is_unemployed'] = (learn_data['act'] == 'TACT1_2').astype(int)\n",
    "\n",
    "learn_data.loc[learn_data['JOB_42'].str.startswith('csp_7', na=False), 'JOB_42'] = learn_data['FORMER_JOB_42']\n",
    "\n",
    "learn_data = learn_data.drop(columns=[\"act\", \"former_emp_contract\", \"RETIREMENT_PAY\", \"FORMER_JOB_42\", \"Economic_sector\", \"Code\", \"Libellé\", \"Nomenclature\"])\n",
    "#or keep nomenclature, remove economic_sector_num\n",
    "\n",
    "learn_data[\"JOB_42\"] = learn_data[\"JOB_42\"].str.extract(r'csp_(\\d+)_')[0].astype(int)\n",
    "learn_data[\"Employer_category\"] = learn_data[\"Employer_category\"].str.extract(r'ct_(\\d)')[0].astype(\"Int64\")\n",
    "learn_data[\"employee_count\"] = learn_data[\"employee_count\"].str.extract(r'tr_(\\d)')[0].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types\n",
    "learn_data[\"sex\"] = pd.factorize(learn_data[\"sex\"])[0]\n",
    "learn_data[\"studying\"] = learn_data[\"studying\"].astype(\"int64\")\n",
    "learn_data[\"Sports_Category\"] = pd.to_numeric(learn_data[\"Sports_Category\"], errors='coerce').astype(\"Int64\")\n",
    "#or learn_data[\"Sports_Category\"] = learn_data[\"Sports_Category\"].fillna(0).astype(\"int64\")\n",
    "learn_data[\"REG_JOB\"] = pd.to_numeric(learn_data[\"REG_JOB\"], errors='coerce').astype('Int64')\n",
    "learn_data[\"REG_FORMER\"] = pd.to_numeric(learn_data[\"REG_FORMER\"], errors='coerce').astype('Int64')\n",
    "learn_data[\"retirement_age\"] = pd.to_numeric(learn_data[\"retirement_age\"], errors='coerce').astype('Int64')\n",
    "learn_data[\"WORKING_HOURS\"] = pd.to_numeric(learn_data[\"WORKING_HOURS\"], errors='coerce').astype('Int64')\n",
    "learn_data[\"Economic_sector_num\"] = pd.to_numeric(learn_data[\"Economic_sector_num\"], errors='coerce').astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def household_num(value):\n",
    "    parts = value.split('|')  # Split the value by '|'\n",
    "    if parts[1] in {'1', '2', '3'}:  # For M|1|-- to M|3|--\n",
    "        return int(parts[1])\n",
    "    elif parts[1] == '4':  # For M|4|1 to M|4|4\n",
    "        return 4 + (int(parts[2]) - 1)  # 4 + (1-1), 4 + (2-1), etc.\n",
    "    return None  # Handle unexpected cases gracefully\n",
    "\n",
    "code_HOUSEHOLD_TYPE['HOUSEHOLD_TYPE_num'] = code_HOUSEHOLD_TYPE['Code'].apply(household_num)\n",
    "learn_data['HOUSEHOLD_TYPE'] = learn_data['HOUSEHOLD_TYPE'].apply(household_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do one-hot-encoding for WORK_CONDITION, TYPE_OF_CONTRACT, labor_force_status\n",
    "\n",
    "figure out highest credentials simplification?\n",
    "\n",
    "consider making pay categorical as well with eg tax level boundaries?\n",
    "\n",
    "link dep to INSEE code for missing ones\n",
    "\n",
    "for all now numerical cats but with missing values, can do +1 and make fillna as 0\n",
    "\n",
    "note: TACT2_3 doesn't exist in dataset - no under 14 year olds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY              int64\n",
       "sex                      int64\n",
       "JOB_42                   int64\n",
       "HIGHEST_CREDENTIAL      object\n",
       "studying                 int64\n",
       "INSEE_CODE              object\n",
       "age_2020                 int64\n",
       "HOUSEHOLD_TYPE           int64\n",
       "target                 float64\n",
       "emp_contract            object\n",
       "Pay                    float64\n",
       "retirement_age           Int64\n",
       "REG_FORMER               Int64\n",
       "Sports_Category          Int64\n",
       "Employer_category        Int64\n",
       "employee_count           Int64\n",
       "TYPE_OF_CONTRACT        object\n",
       "WORK_CONDITION          object\n",
       "labor_force_status      object\n",
       "WORKING_HOURS            Int64\n",
       "REG_JOB                  Int64\n",
       "Economic_sector_num      Int64\n",
       "work_description         Int64\n",
       "is_retired               int64\n",
       "is_unemployed            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_data.dtypes #maybe working hours?, retirement age, (retirement) pay, should be int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(df):\n",
    "        mis_val = df.isnull().sum()\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)  #% of missing values\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)  #create result table\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        print (\"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        return mis_val_table_ren_columns\n",
    "\n",
    "print(missing_values_table(learn_data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for job_42 cats csp_1 and 2 have emp_contract but missing data for all other job stuff\n",
    "# and for csp_8 have missing data for all job stuff \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOR employee_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no longer necessary? - employee count now numerical\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(learn_data.loc[:,\"employee_count\"])\n",
    "dict(zip(le.classes_, le.transform(le.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_data['employee_count_encoded'] = le.transform(learn_data['employee_count'])\n",
    "learn_data['employee_count_encoded'] = learn_data['employee_count_encoded'].map(lambda x: np.nan if x==7 else x)\n",
    "df_train = learn_data.loc[:,[\"PRIMARY_KEY\", \"employee_count_encoded\",\"studying\", \"WORKING_HOURS\", \"age_2020\",\"Pay\", \"retirement_age\",\"RETIREMENT_PAY\",\n",
    "                             \"Sports_Category\", \"REG_JOB\",\"REG_FORMER_JOB\"]]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputer = IterativeImputer(random_state=100)\n",
    "#imputer.fit(df_train)\n",
    "#df_imputed = imputer.transform(df_train)\n",
    "knn_imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "knn_imputer.fit(df_train)\n",
    "df_imputed = knn_imputer.transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_data.loc[:,\"employee_count_encoded\"] = df_imputed[:,1].round()\n",
    "count_imputed = list(le.inverse_transform(learn_data['employee_count_encoded'].round().astype('int')))\n",
    "learn_data[\"employee_count_encoded\"] = count_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
